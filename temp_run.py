#!/usr/bin/env python3
"""
äº¤äº’å¼é€æ­¥è¿è¡Œ LangGraph é“¾è·¯
æ¯æ‰§è¡Œå®Œä¸€ä¸ªèŠ‚ç‚¹ï¼Œå…ˆå‘Šè¯‰ç”¨æˆ·ï¼Œç­‰ç”¨æˆ·åŒæ„åå†å¾€ä¸‹ç»§ç»­
æ¯æ­¥ç»“æœä¿å­˜åˆ°æ–‡ä»¶ä¸­ä¾›äººå·¥æ£€æŸ¥
"""

import sys
import os
import json
from typing import Dict, Any, Optional
from datetime import datetime
from pathlib import Path

from dotenv import load_dotenv

from tradingagents.graph.trading_graph import TradingAgentsGraph
from tradingagents.default_config import DEFAULT_CONFIG

# Load environment variables
load_dotenv()

# åˆ›å»ºè¾“å‡ºç›®å½•
OUTPUT_DIR = Path("langgraph_outputs")
OUTPUT_DIR.mkdir(exist_ok=True)


def save_step_output(step_count: int, node_name: str, chunk: Any):
    """
    ä¿å­˜æ­¥éª¤è¾“å‡ºåˆ°æ–‡ä»¶
    
    Args:
        step_count: æ­¥éª¤ç¼–å·
        node_name: èŠ‚ç‚¹åç§°
        chunk: èŠ‚ç‚¹è¾“å‡º
    """
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = OUTPUT_DIR / f"step_{step_count:02d}_{node_name.replace(' ', '_')}_{timestamp}.json"
    
    output_data = {
        "step_count": step_count,
        "node_name": node_name,
        "timestamp": timestamp,
        "chunk": {}
    }
    
    if isinstance(chunk, dict):
        for key, value in chunk.items():
            if key == "messages":
                output_data["chunk"]["messages"] = []
                for msg in value:
                    msg_dict = {
                        "type": type(msg).__name__,
                        "content": msg.content if hasattr(msg, "content") else str(msg),
                    }
                    if hasattr(msg, "tool_calls"):
                        msg_dict["tool_calls"] = str(msg.tool_calls)
                    output_data["chunk"]["messages"].append(msg_dict)
            elif key in ["investment_debate_state", "risk_debate_state"]:
                output_data["chunk"][key] = dict(value) if hasattr(value, "items") else str(value)
            else:
                output_data["chunk"][key] = str(value)[:5000] if isinstance(value, str) else str(value)
    
    with open(filename, "w", encoding="utf-8") as f:
        json.dump(output_data, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {filename}")
    
    # åŒæ—¶ä¿å­˜ä¸€ä»½çº¯æ–‡æœ¬æ ¼å¼
    txt_filename = OUTPUT_DIR / f"step_{step_count:02d}_{node_name.replace(' ', '_')}_{timestamp}.txt"
    with open(txt_filename, "w", encoding="utf-8") as f:
        f.write(f"=== Step {step_count}: {node_name} ===\n")
        f.write(f"Timestamp: {timestamp}\n\n")
        
        if isinstance(chunk, dict):
            for key, value in chunk.items():
                if key == "messages" and value:
                    f.write(f"--- Messages ---\n")
                    for i, msg in enumerate(value):
                        f.write(f"\nMessage {i+1} ({type(msg).__name__}):\n")
                        if hasattr(msg, "content"):
                            f.write(msg.content)
                            f.write("\n")
                elif key in ["market_report", "fundamentals_report", "candlestick_report", 
                           "investment_plan", "trader_investment_plan", "final_trade_decision",
                           "sentiment_report", "news_report"]:
                    f.write(f"\n--- {key} ---\n")
                    f.write(str(value))
                    f.write("\n")
    
    print(f"ğŸ’¾ æ–‡æœ¬æ ¼å¼å·²ä¿å­˜åˆ°: {txt_filename}")


def step_prompt(step_count: int, node_name: str, chunk: Any = None) -> bool:
    """
    è¯¢é—®ç”¨æˆ·æ˜¯å¦ç»§ç»­æ‰§è¡Œä¸‹ä¸€æ­¥
    
    Args:
        step_count: æ­¥éª¤ç¼–å·
        node_name: èŠ‚ç‚¹åç§°
        chunk: èŠ‚ç‚¹è¾“å‡º
        
    Returns:
        True è¡¨ç¤ºç»§ç»­ï¼ŒFalse è¡¨ç¤ºåœæ­¢
    """
    print("\n" + "=" * 120)
    print(f"âœ… æ­¥éª¤ {step_count} - èŠ‚ç‚¹æ‰§è¡Œå®Œæˆ: {node_name}")
    print("=" * 120)
    
    # ä¿å­˜è¾“å‡º
    save_step_output(step_count, node_name, chunk)
    
    if chunk and isinstance(chunk, dict):
        # æ˜¾ç¤ºå…³é”®ä¿¡æ¯
        if "messages" in chunk and chunk["messages"]:
            last_msg = chunk["messages"][-1]
            print(f"\nğŸ“ æœ€åä¸€æ¡æ¶ˆæ¯é¢„è§ˆ:")
            print("-" * 120)
            if hasattr(last_msg, "content"):
                content = last_msg.content
                if len(content) > 2000:
                    print(content[:2000] + "\n...\n[å†…å®¹å·²æˆªæ–­ï¼Œè¯·æŸ¥çœ‹ä¿å­˜çš„æ–‡ä»¶]")
                else:
                    print(content)
            print("-" * 120)
        
        # æ˜¾ç¤ºæŠ¥å‘Šå­—æ®µ
        report_fields = [
            "market_report", "fundamentals_report", "candlestick_report",
            "sentiment_report", "news_report",
            "investment_plan", "trader_investment_plan", "final_trade_decision"
        ]
        for field in report_fields:
            if field in chunk and chunk[field]:
                print(f"\nğŸ“„ {field} å·²ç”Ÿæˆ")
    
    print("\n" + "-" * 120)
    
    while True:
        return True  # è‡ªåŠ¨ç»§ç»­
        response = input("\næ˜¯å¦ç»§ç»­æ‰§è¡Œä¸‹ä¸€ä¸ªèŠ‚ç‚¹? (y/n): ").strip().lower()
        if response in ["y", "yes", "æ˜¯"]:
            return True
        elif response in ["n", "no", "å¦"]:
            return False
        else:
            print("è¯·è¾“å…¥ y (ç»§ç»­) æˆ– n (åœæ­¢)")


def run_interactive_steps():
    """äº¤äº’å¼é€æ­¥è¿è¡Œ LangGraph é“¾è·¯"""
    print("ğŸš€ TradingAgents LangGraph äº¤äº’å¼é€æ­¥è¿è¡Œ")
    print("=" * 120)
    
    # ä½¿ç”¨ä»Šå¤©çš„æ—¥æœŸ
    trade_date = datetime.today().strftime("%Y-%m-%d")
    target_symbol = "LMND"
    
    print(f"ğŸ“… äº¤æ˜“æ—¥æœŸ: {trade_date}")
    print(f"ğŸ“Š ç›®æ ‡è‚¡ç¥¨: {target_symbol}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {OUTPUT_DIR.absolute()}")
    print("=" * 120)
    
    # åˆå§‹åŒ–
    print("\nâš™ï¸  æ­£åœ¨åˆå§‹åŒ– TradingAgentsGraph...")
    ta = TradingAgentsGraph(
        debug=True,
        config=DEFAULT_CONFIG,
        selected_analysts=["market", "social", "news", "fundamentals", "candlestick"]
    )
    print("âœ… åˆå§‹åŒ–å®Œæˆ")
    
    # åˆ›å»ºåˆå§‹çŠ¶æ€
    init_agent_state = ta.propagator.create_initial_state(target_symbol, trade_date)
    args = ta.propagator.get_graph_args()
    
    print("\n" + "=" * 120)
    print("ğŸš€ å¼€å§‹é€æ­¥æ‰§è¡Œ LangGraph é“¾è·¯...")
    print("=" * 120)
    
    try:
        final_state = None
        step_count = 0
        
        # ä½¿ç”¨ stream() é€èŠ‚ç‚¹æ‰§è¡Œ
        for chunk in ta.graph.stream(init_agent_state, **args):
            step_count += 1
            
            # è·å–èŠ‚ç‚¹åç§°
            node_name = list(chunk.keys())[0] if chunk else "Unknown"
            
            print(f"\nğŸ“Š æ­¥éª¤ {step_count}: æ‰§è¡ŒèŠ‚ç‚¹ '{node_name}'")
            
            # æ˜¾ç¤ºèŠ‚ç‚¹è¾“å‡ºå¹¶è¯¢é—®æ˜¯å¦ç»§ç»­
            if not step_prompt(step_count, node_name, chunk):
                print("\nğŸ‘‹ ç”¨æˆ·å–æ¶ˆæ‰§è¡Œ")
                return
            
            final_state = chunk
        
        # æ‰§è¡Œå®Œæˆ
        print("\n" + "=" * 120)
        print("ğŸ‰ æ‰€æœ‰èŠ‚ç‚¹æ‰§è¡Œå®Œæˆ!")
        print("=" * 120)
        
        if final_state:
            # ä¿å­˜æœ€ç»ˆçŠ¶æ€
            final_filename = OUTPUT_DIR / f"final_state_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            with open(final_filename, "w", encoding="utf-8") as f:
                save_dict = {}
                for key, value in final_state.items():
                    if key == "messages":
                        save_dict[key] = []
                        for msg in value:
                            save_dict[key].append({
                                "type": type(msg).__name__,
                                "content": msg.content if hasattr(msg, "content") else str(msg)
                            })
                    elif key in ["investment_debate_state", "risk_debate_state"]:
                        save_dict[key] = dict(value)
                    else:
                        save_dict[key] = str(value)
                json.dump(save_dict, f, indent=2, ensure_ascii=False)
            print(f"\nğŸ’¾ æœ€ç»ˆçŠ¶æ€å·²ä¿å­˜åˆ°: {final_filename}")
            
            # å¤„ç†æœ€ç»ˆä¿¡å·
            decision = ta.process_signal(final_state.get("final_trade_decision", ""))
            print(f"\nğŸ“Š æœ€ç»ˆå†³ç­–:")
            print(decision)
            
            # æ˜¾ç¤ºå…³é”®æŠ¥å‘Š
            print("\n" + "=" * 120)
            print("ğŸ“‹ å…³é”®æŠ¥å‘Šæ‘˜è¦:")
            print("=" * 120)
            
            for field in ["market_report", "fundamentals_report", "candlestick_report", 
                         "sentiment_report", "news_report"]:
                if final_state.get(field):
                    print(f"\nğŸ“„ {field}:")
                    print("-" * 120)
                    report = final_state[field]
                    print(report[:1000] + "..." if len(report) > 1000 else report)
            
            if final_state.get("investment_plan"):
                print("\nğŸ’° æŠ•èµ„è®¡åˆ’:")
                print("-" * 120)
                print(final_state["investment_plan"])
            
            if final_state.get("final_trade_decision"):
                print("\nğŸ¯ æœ€ç»ˆäº¤æ˜“å†³ç­–:")
                print("-" * 120)
                print(final_state["final_trade_decision"])
        
    except Exception as e:
        print(f"\nâŒ æ‰§è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        
        # ä¿å­˜é”™è¯¯ä¿¡æ¯
        error_filename = OUTPUT_DIR / f"error_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        with open(error_filename, "w", encoding="utf-8") as f:
            f.write(f"Error: {e}\n\n")
            f.write(traceback.format_exc())
        print(f"\nğŸ’¾ é”™è¯¯ä¿¡æ¯å·²ä¿å­˜åˆ°: {error_filename}")
        
        return


if __name__ == "__main__":
    run_interactive_steps()
