#!/usr/bin/env python3
"""
TradingAgents è¿è¡Œè„šæœ¬
ç”¨æ³•: python run_trading.py [è‚¡ç¥¨ä»£ç ] [æ—¥æœŸ] [é€‰é¡¹]
ç¤ºä¾‹: python run_trading.py LMND 2026-02-20
      python run_trading.py AAPL --llm-provider anthropic --deep-think claude-sonnet-4-20250514

æ—¥å¿—è¾“å‡º: logs/{symbol}-{date}-h.log
"""

import sys
import os
import argparse
from datetime import datetime
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, BASE_DIR)

# å°è¯•ä½¿ç”¨é¡¹ç›®è‡ªå¸¦çš„ .venv
VENV_PYTHON = os.path.join(BASE_DIR, ".venv", "bin", "python")
if os.path.exists(VENV_PYTHON):
    # å¦‚æœè¿è¡Œçš„æ˜¯ç³»ç»Ÿ pythonï¼Œé‡æ–°ç”¨ venv çš„ python æ‰§è¡Œ
    if sys.executable != VENV_PYTHON:
        print(f"æ£€æµ‹åˆ°é¡¹ç›®è™šæ‹Ÿç¯å¢ƒï¼Œæ­£åœ¨åˆ‡æ¢...")
        os.execv(VENV_PYTHON, [VENV_PYTHON] + sys.argv)

from dotenv import load_dotenv
from tradingagents.graph.trading_graph import TradingAgentsGraph
from tradingagents.default_config import DEFAULT_CONFIG

# åŠ è½½ .env ç¯å¢ƒå˜é‡
load_dotenv()

# å¯ç”¨åˆ†æå¸ˆåˆ—è¡¨
AVAILABLE_ANALYSTS = ["market", "social", "news", "fundamentals", "candlestick"]
# å¯ç”¨ LLM æä¾›å•†
AVAILABLE_PROVIDERS = ["openai", "anthropic", "google", "xai", "openrouter", "ollama"]

def run_trading_analysis(
    symbol: str,
    date: str,
    debug: bool = True,  # é»˜è®¤å¼€å¯ debug
    llm_provider: str = None,
    deep_think_llm: str = None,
    quick_think_llm: str = None,
    backend_url: str = None,
    max_debate_rounds: int = None,
    analysts: list = None,
    output_lang: str = None,
):
    """
    è¿è¡Œäº¤æ˜“åˆ†æ

    Args:
        symbol: è‚¡ç¥¨ä»£ç 
        date: åˆ†ææ—¥æœŸ
        debug: æ˜¯å¦å¼€å¯ debug æ¨¡å¼ (é»˜è®¤ True)
        llm_provider: LLM æä¾›å•† (ä» .env è¯»å–æˆ–æŒ‡å®š)
        deep_think_llm: æ·±åº¦æ€è€ƒæ¨¡å‹
        quick_think_llm: å¿«é€Ÿæ€è€ƒæ¨¡å‹
        backend_url: API ç«¯ç‚¹
        max_debate_rounds: è¾©è®ºè½®æ•°
        analysts: åˆ†æå¸ˆåˆ—è¡¨
        output_lang: è¾“å‡ºè¯­è¨€
    """
    # è®¾ç½®æ—¥å¿—æ–‡ä»¶è¾“å‡º
    log_dir = os.path.join(BASE_DIR, "logs")
    os.makedirs(log_dir, exist_ok=True)
    log_file = os.path.join(log_dir, f"{symbol}-{date}-h.log")
    
    # å¦‚æœæ²¡æœ‰è®¾ç½® stdout åˆ°æ–‡ä»¶ï¼Œåˆ™åŒæ—¶è¾“å‡ºåˆ°æ—¥å¿—æ–‡ä»¶å’Œæ§åˆ¶å°
    import logging
    logging.basicConfig(
        level=logging.DEBUG if debug else logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),
            logging.StreamHandler()
        ]
    )
    
    print(f"\n{'='*50}")
    print(f"TradingAgents åˆ†æ")
    print(f"è‚¡ç¥¨: {symbol}")
    print(f"æ—¥æœŸ: {date}")
    print(f"Debug: {'å¼€å¯' if debug else 'å…³é—­'}")
    print(f"æ—¥å¿—: {log_file}")
    print(f"{'='*50}\n")

    # åˆ›å»ºé…ç½®ï¼ˆé»˜è®¤å…³é—­ debugï¼‰
    config = DEFAULT_CONFIG.copy()

    # Debug é…ç½®
    config["debug"] = {
        "enabled": debug,
        "verbose": debug,
        "show_prompts": debug,
        "log_level": "INFO" if not debug else "DEBUG",
    }

    # LLM é…ç½®ï¼ˆå‘½ä»¤è¡Œå‚æ•°ä¼˜å…ˆï¼Œå¦åˆ™ç”¨ .env/é»˜è®¤å€¼ï¼‰
    if llm_provider:
        config["llm_provider"] = llm_provider
        print(f"ğŸ“¡ LLM æä¾›å•†: {llm_provider}")
    else:
        print(f"ğŸ“¡ LLM æä¾›å•†: {config['llm_provider']} (é»˜è®¤)")

    if deep_think_llm:
        config["deep_think_llm"] = deep_think_llm
        print(f"ğŸ§  æ·±åº¦æ€è€ƒæ¨¡å‹: {deep_think_llm}")
    else:
        print(f"ğŸ§  æ·±åº¦æ€è€ƒæ¨¡å‹: {config['deep_think_llm']} (é»˜è®¤)")

    if quick_think_llm:
        config["quick_think_llm"] = quick_think_llm
    elif config.get("quick_think_llm"):
        print(f"âš¡ å¿«é€Ÿæ€è€ƒæ¨¡å‹: {config['quick_think_llm']} (é»˜è®¤)")

    if backend_url:
        config["backend_url"] = backend_url

    if max_debate_rounds is not None:
        config["max_debate_rounds"] = max_debate_rounds
        config["max_risk_discuss_rounds"] = max_debate_rounds
        print(f"ğŸ”„ è¾©è®ºè½®æ•°: {max_debate_rounds}")

    if output_lang:
        config["output_language"] = output_lang
        print(f"ğŸŒ è¾“å‡ºè¯­è¨€: {output_lang}")
    else:
        print(f"ğŸŒ è¾“å‡ºè¯­è¨€: {config.get('output_language', 'zh')} (é»˜è®¤)")

    # åˆ†æå¸ˆé€‰æ‹©
    if analysts:
        selected_analysts = analysts
    else:
        selected_analysts = ["market", "social", "news", "fundamentals", "candlestick"]
    print(f"ğŸ“Š åˆ†æå¸ˆ: {', '.join(selected_analysts)}")

    print()

    # åˆå§‹åŒ–å›¾
    print("æ­£åœ¨åˆå§‹åŒ– TradingAgents...")
    ta = TradingAgentsGraph(
        selected_analysts=selected_analysts,
        debug=debug,
        config=config,
    )

    # è¿è¡Œåˆ†æ
    print(f"\nå¼€å§‹åˆ†æ {symbol} ({date})...\n")
    try:
        graph_state, decision = ta.propagate(symbol, date)

        print(f"\n{'='*50}")
        print(f"âœ… åˆ†æå®Œæˆï¼")
        print(f"æœ€ç»ˆå†³ç­–: {decision}")
        print(f"{'='*50}\n")

        return graph_state, decision

    except Exception as e:
        print(f"\nâŒ è¿è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return None, None


def main():
    """å‘½ä»¤è¡Œä¸»å…¥å£"""
    parser = argparse.ArgumentParser(
        description="TradingAgents è‚¡ç¥¨åˆ†æ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  %(prog)s LMND                        # åˆ†æ LMNDï¼Œä»Šå¤©æ—¥æœŸ
  %(prog)s AAPL 2026-02-20             # æŒ‡å®šæ—¥æœŸ
  %(prog)s NVDA --debug                 # å¼€å¯è°ƒè¯•
  %(prog)s MSFT --analysts market news fundamentals  # åªé€‰3ä¸ªåˆ†æå¸ˆ
  %(prog)s TSLA --llm-provider anthropic --deep-think claude-sonnet-4-20250514

å¯ç”¨åˆ†æå¸ˆ: market, social, news, fundamentals, candlestick
å¯ç”¨æä¾›å•†: openai, anthropic, google, xai, openrouter, ollama
        """
    )

    parser.add_argument("symbol", nargs="?", default="LMND", help="è‚¡ç¥¨ä»£ç  (é»˜è®¤: LMND)")
    parser.add_argument("date", nargs="?", default=None, help="åˆ†ææ—¥æœŸ YYYY-MM-DD (é»˜è®¤: ä»Šå¤©)")

    # é€‰é¡¹
    parser.add_argument("--debug", action="store_true", help="å¼€å¯è°ƒè¯•æ¨¡å¼")
    parser.add_argument("--analysts", nargs="+", help="é€‰æ‹©çš„åˆ†æå¸ˆ (å¦‚: market news fundamentals)")
    parser.add_argument("--llm-provider", "--provider", dest="llm_provider",
                        help="LLM æä¾›å•† (openai/anthropic/google/xai/openrouter/ollama)")
    parser.add_argument("--deep-think", dest="deep_think_llm", help="æ·±åº¦æ€è€ƒæ¨¡å‹")
    parser.add_argument("--quick-think", dest="quick_think_llm", help="å¿«é€Ÿæ€è€ƒæ¨¡å‹")
    parser.add_argument("--backend-url", dest="backend_url", help="API ç«¯ç‚¹ URL")
    parser.add_argument("--debate-rounds", type=int, default=None, help="è¾©è®ºè½®æ•° (é»˜è®¤: 1)")
    parser.add_argument("--lang", choices=["zh", "en"], help="è¾“å‡ºè¯­è¨€")

    args = parser.parse_args()

    # é»˜è®¤æ—¥æœŸ
    date = args.date or datetime.now().strftime("%Y-%m-%d")

    run_trading_analysis(
        symbol=args.symbol,
        date=date,
        debug=args.debug,
        llm_provider=args.llm_provider,
        deep_think_llm=args.deep_think_llm,
        quick_think_llm=args.quick_think_llm,
        backend_url=args.backend_url,
        max_debate_rounds=args.debate_rounds,
        analysts=args.analysts,
        output_lang=args.lang,
    )


if __name__ == "__main__":
    main()
